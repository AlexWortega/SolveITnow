{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70198f67-c50c-4239-9f93-58c027748c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ae25b9-1ebf-43ed-a32b-c3a282531d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                              RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForCausalLM, AutoTokenizer, RobertaForMaskedLM)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9e32d4-2e9d-44ad-84cb-ad0fb8ec4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/mnt/opt/alexw/Experements/SolveITnow/leetcode-solutions.json')\n",
    "df['code_with_problem'] = df['code_with_problem'].apply(lambda x: x.split('\\n\\n')[0])\n",
    "df = df[['code_with_problem', 'code_only']]\n",
    "df.columns = ['request', 'code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b161de01-97d3-42a8-b039-bcb81cf9b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['request'] = df['request'].str.replace('#', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc35980c-92d7-4e8a-b520-c1a4e07dfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):   \n",
    "    def __init__(self, encoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        \n",
    "    def forward(self, code_inputs=None, nl_inputs=None): \n",
    "        if code_inputs is not None:\n",
    "            outputs = self.encoder(code_inputs,attention_mask=code_inputs.ne(1))[0]\n",
    "            outputs = (outputs*code_inputs.ne(1)[:,:,None]).sum(1)/code_inputs.ne(1).sum(-1)[:,None]\n",
    "            return torch.nn.functional.normalize(outputs, p=2, dim=1)\n",
    "        else:\n",
    "            outputs = self.encoder(nl_inputs,attention_mask=nl_inputs.ne(1))[0]\n",
    "            outputs = (outputs*nl_inputs.ne(1)[:,:,None]).sum(1)/nl_inputs.ne(1).sum(-1)[:,None]\n",
    "            return torch.nn.functional.normalize(outputs, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb971ae-9ab1-4ae1-8dfd-b745e33aae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer\n",
      "config\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "ft_model = \"unixcoder_final.bin\"\n",
    "model_name_or_path = \"microsoft/unixcoder-base\"\n",
    "print(\"tokenizer\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name_or_path)\n",
    "print(\"config\")\n",
    "config = RobertaConfig.from_pretrained(model_name_or_path)\n",
    "print(\"model\")\n",
    "model = RobertaModel.from_pretrained(model_name_or_path)\n",
    "\n",
    "model = Model(model)\n",
    "checkpoint = torch.load(ft_model, map_location='cuda')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(\"cuda\") #.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fbc311e-ba14-4aba-babe-a68a858c3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(nl, code, code_length=256, nl_length = 128):\n",
    "    code_tokens = tokenizer.tokenize(code)[:code_length-4]\n",
    "    code_tokens =[tokenizer.cls_token,\"<encoder-only>\",tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "    code_ids = tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "    padding_length = code_length - len(code_ids)\n",
    "    code_ids += [tokenizer.pad_token_id]*padding_length\n",
    "    \n",
    "    \n",
    "    nl_tokens = tokenizer.tokenize(nl)[:nl_length-4]\n",
    "    nl_tokens = [tokenizer.cls_token,\"<encoder-only>\",tokenizer.sep_token]+nl_tokens+[tokenizer.sep_token]\n",
    "    nl_ids = tokenizer.convert_tokens_to_ids(nl_tokens)\n",
    "    padding_length = nl_length - len(nl_ids)\n",
    "    nl_ids += [tokenizer.pad_token_id]*padding_length\n",
    "    return code_ids, nl_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17374285-b8f3-465d-a252-5af65da1bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_code_to_features(code, code_length=256):\n",
    "    code_tokens = tokenizer.tokenize(code)[:code_length-4]\n",
    "    code_tokens =[tokenizer.cls_token,\"<encoder-only>\",tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "    code_ids = tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "    padding_length = code_length - len(code_ids)\n",
    "    code_ids += [tokenizer.pad_token_id]*padding_length\n",
    "    return code_ids\n",
    "\n",
    "def convert_nl_to_features(nl, nl_length = 128):\n",
    "    nl_tokens = tokenizer.tokenize(nl)[:nl_length-4]\n",
    "    nl_tokens = [tokenizer.cls_token,\"<encoder-only>\",tokenizer.sep_token]+nl_tokens+[tokenizer.sep_token]\n",
    "    nl_ids = tokenizer.convert_tokens_to_ids(nl_tokens)\n",
    "    padding_length = nl_length - len(nl_ids)\n",
    "    nl_ids += [tokenizer.pad_token_id]*padding_length\n",
    "    return  nl_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6869ba-2857-4d57-b36e-835745be6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    code = data_point[\"code\"]\n",
    "    nl = data_point[\"request\"]\n",
    "    code_ids, nl_ids = convert_examples_to_features(nl, code)\n",
    "    return {\"code_ids\":code_ids, \"nl_ids\":nl_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b72af44a-7b1c-4895-ad9a-8e79c4883fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_ids_to_emmb(code_ids):\n",
    "    code_inputs = torch.tensor([code_ids]).to(device)\n",
    "    with torch.no_grad():\n",
    "        code_vec = model(code_inputs=code_inputs)\n",
    "    return code_vec.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf42d3bf-51e2-4502-ab84-969a88d81b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['code_ids'] = df[\"code\"].apply(convert_code_to_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579faf8e-92cc-402d-98f2-05330dbc9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "df['code_emmb'] = df[\"code_ids\"].apply(code_ids_to_emmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef7a7b14-ed4a-4f3b-ada1-bf4016308ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = \"Given an array of integers `nums` and an integer `target`, return _indices of the two numbers such that they add up to `target`_.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6df29131-4d5c-4112-83b8-be3c5e0c9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(nl, code_vecs, cont_return=7, device='cuda'):\n",
    "    nl_ids = convert_nl_to_features(nl)\n",
    "    nl_inputs = torch.tensor([nl_ids]).to(device)\n",
    "    nl_vecs = []\n",
    "    with torch.no_grad():\n",
    "        nl_vec = model(nl_inputs=nl_inputs) \n",
    "        nl_vecs.append(nl_vec.cpu().numpy())\n",
    "\n",
    "    code_vecs = np.concatenate(code_vecs,0)\n",
    "    nl_vecs = np.concatenate(nl_vecs,0)\n",
    "    scores = np.matmul(nl_vecs,code_vecs.T)\n",
    "    sort_ids = np.argsort(scores, axis=-1, kind='quicksort', order=None)[:,::-1]\n",
    "    return sort_ids[0][:cont_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3428168c-46dc-43b7-9990-7be42994b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sort_ids = get_predict(nl, df['code_emmb'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b41ea1a-541e-485d-8395-ab1cb5a50e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def twoSum(nums, target):\n",
      "    map = {}\n",
      "    for i, num in enumerate(nums):\n",
      "        complement = target - num\n",
      "        if complement in map:\n",
      "            return [map[complement], i]\n",
      "        map[num] = i\n",
      "    return []\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['code'][sort_ids].iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
